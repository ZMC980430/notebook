# Kafka

消息存储在 Topic 中，相当于表。不同类型的消息可以存在同一个主题中。

Topic 包含多个分区，使得 Kafka 可扩展，不同分区存在不同节点上。分区是增长不可变的提交日志，每个日志有一个偏移量，通过偏移量对消息提取。不同分区偏移量可重复。不可通过消息内容对消息进行查找

消息以键值对形式存储，发送消息时不指定消息 key，则消息轮询插入不同分区，指定 key 时保证同key 消息插入相同分区。

分区有副本机制，一个分区有多个副本（Leader，Follower）。主分区有写入和读取操作，副本只能同步主分区。如果副本同步过慢， Kafka会从 ISR（In-Sync Replica）中删除该副本，直到同步进度追赶上来。

集群由多个Broker组成，消息代理，负责消息读写，写入磁盘。一个服务器就有一个broker。每个节点可以有一个Topic的主分区和其他Topic的副本。Broker 负责这个主分区的读写和副本的同步。

## 消息模型

分区是最小并行单位，一个分区同时只能被不同消费者组里的消费者消费，不能被同个消费组的不同消费者消费。这样性能更好，不用加锁。

#### 发布订阅模式

为实现每个消息只被一个消费者消费，可将所有消费组放在一个组里，也可实现负载均衡。同一个生产者发送到同一分区的消息offset一定递增，不同分区则顺序无法保证。

消费时，同一个分区内的消费顺序是一定的，但不同分区的消费顺序是不一定的。为保证顺序，可以设置key，确定会分到同一分区。

#### 消息传递语义

- 最多一次：消息可能丢失，但不会重复发送
- 最少一次：消息不会丢失，但可能重复
- 精确一次：保证服务端能收到且在服务端内不重复

#### 生产者

* send() 异步发送，将消息存入对应分区的缓冲区，立即返回。缓冲区中消息由后台线程完成。在连接建立前，缓冲区内就可以保存多个消息了。
* 同步发送：使用 `RecordMetadata recordMetadata = result.get()` 来阻塞
* 批量发送：设置 `batch.size, linger.ms` 二者满足一个就会立即发送
* 节点返回：acks=0 表示忽略通知，acks=1 表示leader节点收到，但不一定被 follower 写入磁盘 acks=all 或 acks=-1 表示 follower 都收到
* 至多一次：acks=0 或 acks=1
* 至少一次：acks=all 或 acks=-1 此时 retrive > 0

#### 消费者

消费者中的特定主题：_consumer_offsets 保存消费者消费到了哪个主题哪个分区的哪个位置。利于快速恢复

#### 精确一次

需要生产者消费者共同保障

- 生产者需要启用幂等 `enable.idempotence=true` retries会默认为最大，acts必须是all
- 消费者不可以依赖offset避免重复消费，需要在消息中添加唯一ID，如订单号，保证不会被重复消费。

## 事务消息

消息会尽可能发送到服务端，如果事务失败，消息仍然会被读到。`isolation-level` 参数设为 read committed，可以避免脏读。

## 消息队列

### 消息队列的作用

- 解耦：每个模块将消息发送至MQ则任务完成，即使后续模块出现问题也不会影响其他模块
- 异步：每个模块对其他模块的调用使用MQ完成，不需等待调用结果的返回
- 流量削峰填谷：如果一个模块的最高并发量比峰值并发量低，可以通过MQ用时间换空间。如果增加机器成本较高。

### 消息队列的比较

|    MQ    | 单机性能 |   持久化   | 支持语言 | 综合                                                                                         |
| :------: | :------: | :--------: | :------: | -------------------------------------------------------------------------------------------- |
| ActiveMQ |   6000   | 性能会下降 |   主流   | 缺乏大规模应用                                                                               |
| RabbitMQ |  12000  | 性能会下降 |   主流   | 高可用 （Erlang的支持）管理界面好用<br />内部机制复杂，集群不支持动态扩展                    |
| RocketMQ |  100000  |  天生支持  |   Java   | 模型简单、接口易用，有大规模应用，性能较好。支持很多功能，定时任务等。<br />缺点：支持Java   |
|  Kafka  | 1000000 |  天生支持  |   主流   | 天生分布式，性能最好，对大数据支持好。<br />运维难度大，对带宽有要求（多副本时对网络要求高） |

### Kafka 特性

- 支持消息持久化
- 高吞吐量，单机百万级
- 扩展性强，可以不停机扩展
- 多客户端支持
- Kafka Stream 流处理，在应对大数据时效果好
- 安全机制，生产消费时有很多保障
- 数据备份，不仅可以做生产消费
- 轻量级，多平台，可以不安装 Zookeeper
- 消息压缩，可以自定义压缩算法

## Kafka 常见参数

config/server.properties

- broker.id 集群下节点的唯一标识。ip 变化 id 不变。
- listeners 监听列表，hostname 为 0.0.0.0 表示监听所有网卡地址，为空则监听默认网卡。
- zookeeper.connect zookeeper 集群地址，可以是多个
- log.dirs 消息保存在磁盘上，存放目录的配置。可配置多路径，会将同分区的日志片段保存在同一路径下，向有最少分区的路径下新增分区
- auto.create.topics.enable 是否自动创建主题。生产者或消费者在请求不存在的主题时是否创建。

## zookeeper

大于 2.8 时，kafka 可以不配置zookeeper，kafka 会自带。

kafka with kraft：kraft 可以生成唯一 ID 保存在磁盘中。

## 消息队列缺点

可用性降低：mq出问题整个系统都崩溃

复杂性提高：要设计生产者消费者，要处理消息重复的问题

一致性问题：消息丢失消息重复

Kafka不支持定时消息。

flink 和 kafka 做数据异构

为什么kafka不支持读写分离：主从分离可能导致数据不一致，

## kafka 有序消费

生产者根据 key 取模决定存储在哪个分区里，存储在分区的消息是有序的。如果一个主题内的消息被分别存放到三个分区中，三个消费者被指派到对应分区，可能会导致不同消费者消费三个分区的消息顺序与生产顺序不同。自定义路由算法，保证同一个key存放在同一个分区。消费者可能会异步处理消息，不同线程处理效率不同，可能会导致不同消息处理顺序不同。

## ISR

为了保证消息可靠存储，消息会存在leader分区和follower分区，在多副本设计方案中，数据同步和新leader选举，ISR保存和leader数据最接近的follower节点列表，保证同步效率和数据丢失。

## kafka 的 pull push

pull 是消费者主动拉去消息，根据自身处理速度来进行控制，但可能拉到的消息为空。

push 是broker主动向消费者推送数据，但消费者不一定有能力处理，可能导致网络阻塞，消费者压力大。

## kafka 高性能高吞吐的原因（适合海量日志）

- 磁盘顺序读写，比随机读写效率高。因为会预读，顺序读写可以充分利用这个特点。利用磁盘也可以堆积大量消息，比基于内存的MQ能多存储更多消息
- 零拷贝，避免两次的用户态内核态内存拷贝以及上下文切换的开销
- 分区分段+索引：topic的消息通过分区存储在broker中，kafka的消息实际上是分布式存储在一个个 segment 中，每次文件操作是针对单个 segment 文件进行存储。对分段建立索引，就可以很快找到分段的位置，再通过偏移量就能找到消息。为了避免并发问题，单个segment会加锁，保证单一线程访问。但因为锁只锁定一个分段，不会影响其他分段，可以保证并发度。
- 多条消息在网络传输时会压缩，可以降低带宽。
- 批量读写：消息是批量发送
- kafka 是基于JVM，但可以直接操作 page cache，避免GC耗时和对象创建的耗时，读写速度更快，进程重启也不会导致缓存丢失。
